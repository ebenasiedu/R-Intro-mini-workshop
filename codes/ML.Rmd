---
title: "Machine Learning"
date: "2022-12-16"
output: html_document
---


```{r setup, include=FALSE, message=FALSE}
library(tidymodels)
library(data.table)
library(dplyr)
library(purrr)
library(tidyverse)
library(reshape2)
library(ggplot2)
library(pheatmap)
library(plyr)
library(tidyr)
library(ggrepel)
library(ggsci)
library(viridis)
library(vip)
library(usemodels)
library(keras)
library(xgboost)
library(ranger)


knitr::opts_chunk$set(echo = TRUE)

```


#  {.tabset}

## Data Prep {.tabset}

```{r, message=FALSE, warning=FALSE}
setwd("C:/Users/ebenezer.asiedu/Desktop/Bioinfo/PROJECT/01/AD_LGG")
fox <- read.delim("FOXO_target genes.txt", header = T)
setwd("C:/Users/ebenezer.asiedu/Desktop/Bioinfo/PROJECT/01/Analysis/Expression_data")
directory <- getwd()
files <- list.files(directory, pattern ="*.csv")
df <- map(files, .f=fread,header=TRUE,drop = 1)
id = c(1:length(df))
for (i in id){
  df[[id[i]]] <- df[[id[i]]][!duplicated(df[[id[i]]][["Gene"]]),]
  df[[id[i]]] <- merge(fox, df[[id[i]]], by.y="Gene", all=F)
  }
# Get count data
cts <- join_all(df, by = "Gene", match = "all")
cts <- as.data.frame(t(cts))
names(cts) <- cts[1,] 
cts <- cts %>% rownames_to_column(var = "Status")
cts <- cts[-1,] %>% drop_na()
cts$Status = gsub("\\..*","",cts$Status)

head(cts)


data <- cts %>% filter(Status != "CTRL")
  
```


## Model Set-Up {.tabset}

```{r, message=FALSE, warning=FALSE}

# Splitting
set.seed(123)
data_split <- initial_split(data, prop = 0.70, strata = Status)
train_data <- training(data_split)
test_data <- testing(data_split)

#Preprocessing recipe
df_rec <-
  recipe(Status ~ .,data = train_data) %>%
  step_string2factor(one_of("Status")) %>% 
  step_naomit(everything(), skip = TRUE) %>%
  step_novel(all_nominal(), -all_outcomes()) %>%
  step_normalize(all_numeric(), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>%
  step_zv(all_numeric(), -all_outcomes()) %>%
  step_corr(all_predictors(), threshold = 0.7, method = "spearman")


## Re-partitioning training data: 
#Bootstrapping
set.seed(243)
data_boot <- bootstraps(train_data, times = 4, strata = Status)
#k-fold cross validation
set.seed(100)
cv_folds <- vfold_cv(train_data, v = 4, strata = Status)


# Random forest
rf_spec <- rand_forest(trees = 1000) %>% set_engine("ranger", importance = "impurity") %>%
  set_mode("classification")
#Boosted tree (XGBoost)
xgb_spec <- boost_tree() %>% set_engine("xgboost") %>%
  set_mode("classification")
# Neural network
nnet_spec <- mlp() %>% set_mode("classification") %>% set_engine("keras", verbose = 0)


## Create Workflows
# Random forest
rf_wflow <- workflow() %>% add_recipe(df_rec) %>% add_model(rf_spec)
# XGBoost
xgb_wflow <- workflow() %>% add_recipe(df_rec) %>% add_model(xgb_spec)
# Neural network
nnet_wflow <- workflow() %>% add_recipe(df_rec) %>% add_model(nnet_spec)



# Logistic regression
#log_res <- log_wflow %>% fit_resamples(resamples = data_boot,
#                metrics = metric_set(accuracy),
#                control = control_resamples(save_pred = TRUE))
#log_res %>% collect_metrics(summarize = TRUE)
#log_res %>% collect_metrics(summarize = FALSE)
#log_pred <- log_res %>% collect_predictions()
#log_pred %>% conf_mat(Status, .pred_class) %>% autoplot(type = "heatmap") #Conf.Matrix
#log_pred %>% group_by(id) %>% roc_curve(Status, .pred_class) %>% autoplot() #ROC

# Random Forest
rf_res <- rf_wflow %>% fit_resamples(resamples = data_boot,
                metrics = metric_set(accuracy),
                control = control_resamples(save_pred = TRUE))


# XGBoost
xgb_res <- xgb_wflow %>% fit_resamples(resamples = data_boot,
                metrics = metric_set(accuracy),
                control = control_resamples(save_pred = TRUE))


# neural net
nnet_res <- nnet_wflow %>% fit_resamples(resamples = data_boot,
                metrics = metric_set(accuracy),
                control = control_resamples(save_pred = TRUE))

# Collect metrics
rf_res %>% collect_metrics(summarize = TRUE)
#rf_pred <- rf_res %>% collect_predictions()
#rf_pred %>% conf_mat(Status, .pred_class) %>% autoplot(type = "heatmap") #Conf.Matrix
#rf_pred %>% group_by(id) %>% roc_curve(Status, .pred_class) %>% autoplot() #ROC
xgb_res %>% collect_metrics(summarize = TRUE)
#xgb_pred <- xgb_res %>% collect_predictions()
#xgb_pred %>% conf_mat(Status, .pred_class) %>% autoplot(type = "heatmap") #Conf.Matrix
#xgb_pred %>% group_by(id) %>% roc_curve(Status, .pred_class) %>% autoplot() #ROC
nnet_res %>% collect_metrics(summarize = TRUE)
#nnet_pred <- nnet_res %>% collect_predictions()
#nnet_pred %>% conf_mat(Status, .pred_class) %>% autoplot(type = "heatmap") #Conf.Matrix
#nnet_pred %>% group_by(id) %>% roc_curve(Status, .pred_class) %>% autoplot() #ROC


#Compare models
rf_metrics <- rf_res %>% collect_metrics(summarise = TRUE) %>% mutate(model = "Random Forest")
xgb_metrics <- xgb_res %>% collect_metrics(summarise = TRUE) %>% 
  mutate(model = "XGBoost")
nnet_metrics <- nnet_res %>% collect_metrics(summarise = TRUE) %>%
  mutate(model = "Neural Net")

# plot
model_compare <- bind_rows(rf_metrics,xgb_metrics,nnet_metrics)
model_comp <- model_compare %>% dplyr::select(model, .metric, mean, std_err) %>% 
  pivot_wider(names_from = .metric, values_from = c(mean, std_err))

model_comp %>% arrange(mean_accuracy) %>%
  mutate(model = fct_reorder(model, mean_accuracy)) %>%
  ggplot(aes(model, mean_accuracy, fill=model)) + geom_col() +
  coord_flip() + scale_fill_brewer(palette = "Blues") + 
  geom_text(size = 3,aes(label = round(mean_accuracy, 2), 
                         y = mean_accuracy + 0.08), vjust = 1)


```

## Test Model {.tabset}

```{r}
last_fit_rf <- last_fit(rf_wflow, split = data_split, metrics = metric_set(accuracy))
last_fit_rf %>% collect_metrics()
last_fit_rf %>% pluck(".workflow", 1) %>% pull_workflow_fit() %>% vip(num_features = 10)

last_fit_rf %>% collect_predictions() %>%
  conf_mat(Status, .pred_class) %>% autoplot(type = "heatmap")

last_fit_rf %>% collect_predictions() %>% roc_curve(Status, .pred_class) %>% autoplot()

```