---
title: ""
author: ""
output: html_document
editor_options: 
  markdown: 
    wrap: sentence
---

## Machine Learning: the basics {.tabset}

### Intro

-   **Understand the Problem and Goals:** Clearly define your problem: Is it classification, regression, clustering, etc.?
    Understand your data and the domain it represents.
    Define what success looks like: How will you measure the performance of your model?

-   **Data Preprocessing:** Handle missing values: Decide whether to impute, remove, or keep missing data.
    Clean and transform data: Address outliers, normalize/standardize features, and handle categorical variables.
    Feature Selection and Engineering:

-   **Feature engnerring or Selecting relevant features:** Remove irrelevant or redundant features that don't contribute much to the model.
    Create new features if they can provide more information to the model.
    Data Splitting:

-   **Split data into training, validation, and test sets**: Use the training set to train your model, the validation set to tune hyperparameters, and the test set to evaluate the final performance.
    Model Selection:

-   **Choose appropriate algorithms based on your problem type and data characteristics:** Start with simpler models before trying complex ones.
    Model Training:

-   **Fit the chosen model to the training data:** Tune hyperparameters to optimize model performance on the validation set (e.g., using cross-validation).
    Model Evaluation:

-   **Evaluate your model on the test set using appropriate evaluation metrics (accuracy, precision, recall, F1-score, etc.):** Avoid overfitting by ensuring your model generalizes well to new, unseen data.
    Iterate and Improve:

-   **Analyze model errors and consider improving data quality, feature engineering, or selecting a different algorithm:** Refine your model and iterate based on the insights gained from evaluation.
    Interpretability and Visualization:

-   **Visualize and interpret your model's predictions:** Some algorithms are more interpretable than others.
    Visualize data distributions, relationships, and model outputs to gain insights.
    Documentation and Communication:


### Logistic regression

Useful for predicting and giving binary responses.
Real life examples: `spam detection` `heart attack occurrence in patients` `fraudulent transactions`

We are going to practise this with the mtcars data. We want the model to learn the data and do the following for us:
- Tell us which features are relevant to determine the transmission type of the car
- Predict the transmission type of a car for us


```{r}
# Get our data
df <- read.csv(file = "C:/Users/ebenezer.asiedu/Desktop/Grad_Sch/PhD/training/R-miniWorkshop/data/netflix_users.csv")

str(df)
unique(df$Subscription.Type)



df <- df %>% rownames_to_column("cars")

# Inspect your data
any(is.na(df))  # are there incomplete entries in my data
which(is.na(df)) # which colums or rows have NAs

str(df)
# change 0, 1 to automatic and manual
df$am[df$am == 0] <- "automatic"
df$am[df$am == 1] <- "manual"

# convert `am` to factor and set a reference
df$am <- factor(df$am, levels = c("automatic","manual")) # automatic is the reference
str(df)

# Load packages
library(tidymodels) # contain the ML functions
library(mlbench)    # has very cool data suitable for ML


# Split data
df_split <- initial_split(df, prop=0.65, strata=am)

# Create training data
df_train <- df_split %>% training()

# Create training data
df_test <- df_split %>% testing()


## General steps for fitting model with tidymodels

# 1: Call the model function. eg  logistic_reg(), rand_forest(), etc
# 2: Set the engine. eg "glm", "ranger", "xgboost"
# 3: set the mode: "classification", "regression"
# 4: Fit the model; variable ~ . or variable ~ x + y + z ....

## Putting it all together:
df_lr <- logistic_reg() %>%       # model function
  set_engine("glm") %>%           # call engine
  set_mode("classification") %>%  # set mode
  fit(am~., data=df_train)        # fit model

# Generate Summary Table
tidy(df_lr, exponentiate=T)



## Now we use the model for prediction






```

### Random forest

```{r}

# Get our data
df <- datasets::mtcars



```

### k nearest neighbour

```{r}

# Get our data
df <- datasets::mtcars



```

### xgboost

```{r}

# Get our data
df <- datasets::mtcars



```

### neural network

```{r}

# Get our data
df <- datasets::mtcars



```
